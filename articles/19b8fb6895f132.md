---
title: "ローカルLLMとAI-Agentのススメ"
emoji: "🐥"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: []
published: false
---

# ローカルLLMを使いこなそう！

## 前提条件
| 分類 | 使用物 | 
| --- | --- | 
| LLM動作ソフトウェア | LM Studio | 
| 使用LLM | gpt-oss-20b |

これらは事前に導入しておいてください。

# AI-Agentとは
> AI エージェントは、AI を使用してユーザーの代わりに目標を追求し、タスクを完了させるソフトウェア システム
> 推論、計画、メモリーが可能であることが示されており、意思決定、学習、適応を行うレベルの自律性を備えています
https://cloud.google.com/discover/what-are-ai-agents?hl=ja

ということで、AIを使って特定のタスクを、意思決定や学習などの高度な知能を要求タスクを
実行させられるようにするソフトウェアであると認識していればOKです。

## 開発に使用するフレームワーク
今回は、[Mastra](https://github.com/mastra-ai/mastra)というフレームワークを使用して開発する。
```bash
pnpm dlx create-mastra@latest
```

### Mastraとは
[公式ページ](https://mastra.ai/)や[この個人ブログの記事](https://azukiazusa.dev/blog/typescript-ai-agent-framework-mastra/)曰く、
Gatsbyの開発チームが開発したらしい、TypeScript製のAIエージェントフレームワークであるとのこと。
AI エージェントを構築するために必要なプリミティブな機能を提供するために設計されており、
- AIエージェントの定義
    - メモリ使用による過去のコンテキストの保持
    - ツールを使用して外部の情報を取得し、回答の精度を向上
- ワークフローによるステートマシンの構築で複雑な操作を定義
- RAGによって大量のドキュメントをベクトルデータにして、関連情報の検索による精度向上
- MCPとの接続
- Next.jsとの統合

など、様々な機能を提供してくれている

## 作成するもの

今回は、以下のものを作成します。

- 概要
    - 仕様について相談できるAI-Agent
- 接続MCP
    - Sequential-Thinking 
    - Firecrawl
    - Perplexity

### MCP構成について
- Sequential-Thinking 

https://zenn.dev/kimkiyong/articles/c3e22e814dab8a

- Firecrawl

https://zenn.dev/takna/articles/mcp-server-tutorial-08-firecrawl

- Perplexity

https://zenn.dev/takna/articles/mcp-server-tutorial-13-perplexity

### Mastra以外にも必要なライブラリ
- @ai-sdk/openai-compatible

```bash
pnpm add @ai-sdk/openai-compatible
```

https://notes.ideamans.com/posts/2025/mastra-local-llm.html#lm-studio%E3%82%92openai%E4%BA%92%E6%8F%9Bapi%E3%82%B5%E3%83%BC%E3%83%8F%E3%82%99%E3%83%BC%E3%81%AB%E3%81%99%E3%82%8B:~:text=%E3%82%A2%E3%82%AF%E3%82%BB%E3%82%B9%E5%8F%AF%E8%83%BD%E3%81%AB-,Mastra%E3%81%8B%E3%82%89%E4%BD%BF%E3%81%86,-Mastra%E3%81%AFTypeScript

に、このようなコードがあるので、

```typescript
import { createOpenAICompatible } from "@ai-sdk/openai-compatible"

// OpenAI互換ファクトリ
const lmStudio = createOpenAICompatible({
  name: 'lm-studio',
  baseURL: 'http://localhost:1234/v1',
})

// LM Studioでは複数のモデルも同時に提供できるのでIDを揃える
const model = llmStudio('qwen3-30b-a3b')
```

これとほぼ同じような感じで、モデル名だけ
`gpt-oss`に合わせる。

## 実装

### エージェント定義

---
**参考リンク**
https://cloud.google.com/discover/what-are-ai-agents?hl=ja
https://qiita.com/syukan3/items/f5bc8c25a4bf2913f199
https://zenn.dev/robustonian/articles/mastra_ollama_mcp
https://docs.rs/agentai/latest/agentai/
https://qiita.com/youtoy/items/09b953f2f1ef91cb6b6e
https://notes.ideamans.com/posts/2025/mastra-local-llm.html#lm-studio%E3%82%92openai%E4%BA%92%E6%8F%9Bapi%E3%82%B5%E3%83%BC%E3%83%8F%E3%82%99%E3%83%BC%E3%81%AB%E3%81%99%E3%82%8B