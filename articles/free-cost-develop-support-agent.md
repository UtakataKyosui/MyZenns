---
title: "Vibe Codingのコストを抑えるためにできること"
emoji: "💵"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: [llm,vibecoding,mcp,opencode]
published: true
---

# 定額でCodingAgentを利用している中での悩み

最近、個人開発をしていて思ったのが、「一つの機能のウェイトが特別大きいわけでもないのに、作ろうとしているうちにレートリミットが来てしまう」という問題です。

LLMを提供している企業も収益がないとやっていけないので、
月にいくら払ってもらうという契約を締結していたとしても、
ガンガン使い込まれては困るわけです。

APIリクエストを送るたびにコストを払う必要のある従量課金制の手の出しにくさから解放されている定額プランを
使わせてもらっている立場の我々に対して、**LLMの提供者側にかなり譲歩してもらっている契約**であるということは、忘れてはならないことだと思います。

## その中で私たちはどうしてきたか

我々、LLM利用者はそれぞれの点に着目して、
LLMからより良いレスポンスを獲得しようとしてきました。

| 目的 | 改善策 | ツール | 用いられる手法 | 
| --- | --- | --- | --- |
| 機能を着実に<br />完成させたい | 正確に動作するか<br />どうかをチェック | 開発言語で主流と<br />されるテスト手法 | テスト<br />駆動開発 |
| 少ない指示回数で<br />理想的なものを作りたい | LLMへの指示の<br />解像度を高める | Tsumiki<br />Kiro<br />Spec Kit | 仕様駆動開発 |
| LLMにできる物事の範囲を広げたい | LLMと外部システムを<br />連携させる | MCP | 該当なし |

:::message
厳密にはMCPは**プロトコルなので、ツールではない**ですが、
MCPを使って作成されたものはツールとみなして良いと
考えたので、今回はツールに含めました
:::

# これらの工夫でも、避けられないこと

とはいえ、これらはプロンプトのラリーをなるべく減らしたり、
プロンプトのラリーの中で得られるレスポンスの質の向上を果たすことはできますが、
**メインの目的であるCoding以外の用件に対して、
トークンを使用してしまう**ことに変わりはないので、
**コーディングに使えるリクエスト回数を犠牲にしても
十分成果が出せること**が担保できなければ、
それを使っていく理由にはなりづらいです。

## その問題点の解決方法

そこで、私は
「コーディング以外の要件は、**無料で使えるLLMに補助して貰えばいい**んじゃないか？」
と考えました。

有料で優良なLLMと比べたら、精度は落ちるでしょうが、
それでも、ある程度のプロンプトのラリーでなんとかなるのであれば、
試す価値はあると考えました。

仕様の壁打ちやデバッグのための情報収集などは
ある程度無料で利用できるLLMに任せることで、
定額プランへのレートリミットへの到達の回避や
従量課金制で利用しているLLMへのリクエストの数を抑えて
費用を抑えることができるはずです。

## 手順

これらのツールを使うことにします

| 区分 | 対象 |
| --- | --- | 
| Coding Agent Tool | OpenCode |

### `OpenCode`の導入

```sh
curl -fsSL https://opencode.ai/install | bash
```

これを実行したら、
```sh
# Linuxだったらこれが提示される
source ~/.bashrc
# Macだったらこれが提示される
source ~/.zshrc
```

### OpenRouterのLLMを利用する設定をする

```sh
opencode auth login
```
を実行して、`OpenRouter`を選択する

![alt text](/images/image1.png)

ここに、[API Keys | OpenRouter](https://openrouter.ai/settings/keys)で作成した
`API_KEY`を与える

![alt text](/images/image2.png)

そしたら`Done`と表示されて、設定が完了します

### LLMを`OpenCode`で使用する設定を行う

`OpenCode`を起動したら、以下のように`/models`のコマンドを実行します。

![alt text](/images/image.png)

このような選択画面が出るので、
`free`と入力して、無料のモデルを選択してください。

### MCPも足してみよう
`~/.config/opencode/opencode.json`に以下を記載して、
MCPを設定してみよう

```json
{
  "$schema": "https://opencode.ai/config.json",
  "mcp": {
    "sequential-thinking": {
      "type": "local",
      "command": ["npx", "-y", "@modelcontextprotocol/server-sequential-thinking"],
      "enabled": true,
    },
  }
}
```

## 試しに動かしてみる

### MCPを使ったプログラミング以外の相談

`Grok 4 Fast（free）`に、「家の掃除を行う際のコツ」を
`sequential-thinking` MCPを使って考えてもらいました。

```markdown
家の掃除を効率的に行うための要点をまとめました。準備・実行・仕上げの3ステップで、時短とエコを重視。

## 1. 準備段階
- 家をゾーン（キッチン、浴室など）に分け、掃除計画を立てる。
- 多機能道具（マイクロファイバークロス、重曹・酢の自然洗剤）を揃え、ゴミを先に捨ててスペース確保。
- 1日1ゾーンに絞り、タイマーで時間管理。

## 2. 実行段階
- 上から下へ掃除（天井埃 → 床拭き）。
- 汚れ別対応: 埃は乾拭き先、キッチン油汚れはスチーム+重曹、浴室カビはクエン酸+換気。
- ゾーン法で小エリアを徹底。音楽をかけ家族分担でモチベUP。

## 3. 仕上げとメンテナンス
- 道具を即洗浄・収納。
- 毎日5分のクイック掃除を習慣化（リマインダー活用）。
- 化学薬品を避け、ロボット掃除機などの投資で長期時短。
```

ログにはしっかりと
```sh
Sequential-Thinking_sequentialthinking (... 
{
  "thoughtNumber": 5,
  "totalThoughts": 5,
  "nextThoughtNeeded": false,
  "branches": [],
  "thoughtHistoryLength": 5
}
```

とMCPを利用しているのがわかるログが出ていました。

### Zennで出す記事のレビュー

この記事を途中まで書いたものをレビューしてもらうこともしてみました。

```markdown
MCP（sequential-thinking）で深く分析: 問題提起→改善策→無料LLM提案→手順・試用の流れが論理的。定額LLMのレートリミット問題を個人開発視点で解決する実践ガイドとして価値高。

## 強み
- **明確な構造**: テーブルでTDD/SDD/MCPを整理、手順（OpenCodeインストール、MCP設定）がステップバイステップで初心者向け。
- **実用性**: 無料LLM（OpenRouter + Grok free）活用例（掃除コツ生成、開発要件定義）が具体的。MCP統合でテーマ一貫。
- **洞察**: 非コーディングタスクのトークン消費を指摘し、コスト最適化の視点が鋭い。

## 弱み/改善点
- **未完成部分**: 「Zennで出す記事のレビュー」セクションが空。実際のレビュー例を追加。
- **限界の扱い**: 無料モデルの不安定さ（途中で止まる）を触れるが、対処法（プロンプト再試行、モデル切り替え）不足。
- **技術的**: 画像パス（/images/image.png）がローカル依存。Zenn公開時はアップロード確認を。記事長を20%短縮で読みやすく。

## 提案
- 結論部追加: 「非コーディング50%を無料LLMに移行で、有料リミット20-30%延長可能」と定量例。
- MCP活用強化: 記事内でsequential-thinkingの思考ログをさらに例示。
- 全体評価: 8/10。published: trueにし、topicsに「opencode」「mcp」を追加推奨。個人開発者必読のアイデア記事！
```

結構良さげなレビューが返ってきました。
Zennの記事を書いたら、レビューしてもらうために使ってみるのも
一つの選択肢ですね。

### 開発に使用してみる

Spec-Kitの要件定義には、`OpenCode`を利用し、
実装には`Claude Code`を利用することにしました。

これによって、要件定義の部分で`Claude`のレートリミットを
気にすることなく、要件を固めることができます。
実際、使ってみたところ、要件定義を行うことができました。
ただ、**途中で止まってしまう**現象が散見されました。
そのときは、プロンプトの再試行をして継続を試みるか、
モデルを変えて途中停止を回避するか、どちらかを選択して対処する必要が
ありそうです。

この現象については、無料モデルだからなのか、
利用したモデルの特性なのかはまだわかりませんが、
モデルの挙動の調査の余地がありそうです。

# まとめ

無料で使用できるLLMをOpenCodeで利用することによって、
非コーディングタスク実行時に課金を要さないLLMで
MCPやSpec Kitを使った情報収集や要件定義を行うと
多少の挙動の難はありますが、費用を抑えつつ、
それなりの回答を獲得できることがわかりました。
皆さんもこれを試して、よりよい開発に活かしてください。